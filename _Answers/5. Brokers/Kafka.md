## Apache Kafka

### Общая архитектура  
Apache Kafka — распределённая платформа потоковой передачи данных (event streaming). Построена как отказоустойчивая, масштабируемая система для записи, хранения и обработки потоков записей в реальном времени. Основные компоненты:

- **Producer**  
  Отвечает за публикацию сообщений в Kafka. Пакетирует записи (key, value, timestamp) и отправляет в указанные топики.

- **Broker**  
  Сервер Kafka, хранящий часть данных (партиции топиков). Несколько брокеров образуют кластер. Каждый брокер знает состояние других и участвует в координации через контроллер.

- **Topic**  
  Логическая категория для сообщений. Топик разбивается на **партиции** для масштабирования и параллелизма. Пример: топик `orders` может иметь 10 партиций.

- **Partition**  
  Управляемый очередной журнал (append-only log). Каждая запись получает уникальный смещение (offset). Партиции распределяются по брокерам, что повышает отказоустойчивость и пропускную способность.

- **Consumer**  
  Подписывается на один или несколько топиков и читает сообщения последовательно, запоминая смещение. Для масштабирования потребители объединяются в **consumer group**.

- **Consumer Group**  
  Группа потребителей, которые распределяют чтение партиций между собой. Каждая партиция читается только одним членом группы, что обеспечивает балансировку нагрузки.

- **ZooKeeper / KRaft**  
  Ранее Kafka использовала ZooKeeper для хранения метаданных кластера и координации. Начиная с Kafka 2.8+, доступен собственный режим метаданных — **KRaft** (Kafka Raft Metadata Mode) без внешнего ZooKeeper.

---

### Устройство партиций и репликации  
- **Репликация**  
  Каждая партиция имеет один **leader** и N **followers**. Leader принимает записи от продюсеров и отвечает на чтение от потребителей; followers асинхронно копируют данные. При сбое leader’а один из followers становится новым лидером.

- **ISR (In-Sync Replicas)**  
  Список реплик, которые полностью синхронизированы с лидером. Записи считаются сохранёнными только после репликации на все реплики из ISR (если включён `acks=all`).

- **Конфигурация репликации**  
  - `replication.factor` — количество реплик (лидер + followers).  
  - `min.insync.replicas` — минимальное число реплик из ISR для успешного `acks=all` продюсера.

---

### Гарантии доставки и порядковость  
- **Ат-мист (At-Most-Once)**  
  `acks=0` у продюсера: сообщения могут быть потеряны при сбое продюсера или брокера.  

- **По-крайней‑мере‑один‑раз (At-Least-Once)**  
  `acks=all`, повторная отправка при ошибках: дублирование возможно. Потребители обязаны обрабатывать идемпотентно или хранить смещения вручную.

- **Точно‑один‑раз (Exactly-Once Semantics, EOS)**  
  Сочетание идемпотентного продюсера (`enable.idempotence=true`) и управления транзакциями (`transactional.id` у продюсера) + `read_committed` у потребителя. Обеспечивает отсутствие дублей и потерь.

- **Порядковость**  
  Порядок гарантируется внутри одной партиции. Для строгого порядка всех сообщений продюсер должен направлять их в одну партицию (по ключу или явно).

---

### Хранение и ретеншн  
- **Логи**  
  Сообщения хранятся в сегментах на диске в виде файлов. Каждый сегмент закрывается по достижении размера (`segment.bytes`) или времени жизни (`segment.ms`).

- **Политики ретеншн**  
  - **Time-based** (`retention.ms`) — удаление сообщений старше заданного времени.  
  - **Size-based** (`retention.bytes`) — удаление самых старых сегментов при превышении суммарного объёма.  
  - **Log compaction** (`cleanup.policy=compact`) — хранит последнюю запись для каждого ключа, удаляя устаревшие.

- **Tiered storage**  
  Новые возможности (Kafka 3.x+) позволяют хранить старые сегменты в облачных хранилищах (S3, HDFS), разгружая локальный диск при доступности через Kafka API.

---

### Производительность и масштабирование  
- **Параллелизм**  
  Масштабирование за счёт увеличения числа партиций: больше партиций → больше потребителей в группе → более высокая пропускная способность чтения.

- **Производительность продюсера**  
  - `batch.size` и `linger.ms` управляют задержкой и размером батчей.  
  - `compression.type` (gzip, snappy, lz4, zstd) снижает объём передаваемых данных.  

- **Производительность потребителя**  
  - `fetch.min.bytes` и `fetch.max.wait.ms` регулируют размер и задержку выборки.  
  - `max.partition.fetch.bytes` ограничивает объём данных на партицию за один запрос.

- **Аппаратные ресурсы**  
  - Диски SSD повышают I/O производительность.  
  - RAM для кеширования сегментов.  
  - Сеть с низкой задержкой и высокой пропускной способностью.

---

### Безопасность и управление доступом  
- **Аутентификация**  
  - SSL/TLS (SASL_SSL)  
  - SASL SCRAM, SASL PLAIN, Kerberos (SASL_GSSAPI)  

- **Авторизация**  
  - ACL (Access Control Lists) на уровне кластера, топиков и групп потребителей.  

- **Шифрование**  
  - TLS для шифрования трафика между клиентами и брокерами.  
  - Может быть включено в продюсере/потребителе и на уровне inter-broker.

---

### Мониторинг и эксплуатация  
- **Метрики JMX**  
  - Latency, throughput, lag по группам потребителей, состояние реплик, размер очередей.  

- **Мониторинг задержек потребителей**  
  - `consumer_lag` показывает отставание между последним оффсетом в партиции и приведённым смещением потребителя.  
  - Инструменты: Confluent Control Center, Burrow, Prometheus + Grafana.

- **Alerting**  
  - Высокий consumer lag  
  - Реплики вне ISR  
  - Недостаток свободного дискового пространства  
  - Ошибки продюсера (таймауты, отказ реплик)

---

### Инструменты и экосистема  
- **Confluent Platform**  
  Расширения к Kafka: Schema Registry, REST Proxy, KSQL, Control Center.  
- **Kafka Connect**  
  Фреймворк для интеграции с внешними системами: базы данных, файловые системы, облачные сервисы.  
- **Kafka Streams**  
  Библиотека для обработки и трансформации потоков непосредственно в клиентском приложении.  
- **ksqlDB**  
  SQL-подобный интерфейс для определения потоковых обработок и созданий materialized views.  

---

Глубокое понимание принципов работы Kafka — от распределённых журналов до гарантий доставки и масштабирования — позволяет проектировать архитектуры real‑time data pipelines, обеспечивающие надёжность, производительность и гибкость обработки потоков событий. ```
```