### Что такое алгоритмическая сложность  
Алгоритмическая сложность описывает, как растут затраты времени (или памяти) алгоритма при увеличении размера входных данных N. Цель — предсказать, как программа будет себя вести на больших объёмах, выбрать более эффективный подход и сравнить альтернативные решения по масштабируемости.

---

### Большое O, Θ и Ω  
- **O‑нотация (верхняя оценка)**: f(N) = O(g(N)) означает, что при достаточном N время работы f(N) не превосходит C·g(N) для некоторой константы C. Говорит о верхней границе роста.  
- **Θ‑нотация (точная асимптотика)**: f(N) = Θ(g(N)) означает одновременно f(N) = O(g(N)) и g(N) = O(f(N)). Алгоритм растёт пропорционально g(N) при больших N.  
- **Ω‑нотация (нижняя оценка)**: f(N) = Ω(g(N)) означает, что f(N) растёт не быстрее g(N) снизу: f(N) ≥ C·g(N) для больших N.

---

### Время работы: худший, средний, лучший случаи  
1. **Худший случай (Worst‑Case)**  
   Обозначается O‑нотацией. Гарантирует, что алгоритм не будет работать медленнее этой оценки.  
2. **Средний случай (Average‑Case)**  
   Θ‑нотация при среднем входе (зависит от распределения данных).  
3. **Лучший случай (Best‑Case)**  
   Ω‑нотация — минимальное время при «удачном» входе.

---

### Общие классы асимптотик

| Класс             | Пример алгоритмов                              | Описание                                    |
|-------------------|-------------------------------------------------|---------------------------------------------|
| O(1)              | Доступ к элементу массива по индексу            | Константное время                            |
| O(log N)          | Бинарный поиск, сбалансированные деревья        | Логарифмическое, раздваивающее на каждом шаге |
| O(N)              | Линейный проход по массиву                      | Пропорционально размеру входа                |
| O(N log N)        | Быстрая сортировка, сортировка слиянием         | Линейно-логарифмическое                      |
| O(N²)             | Сортировка пузырьком, вложенные циклы           | Квадратичное, два вложенных прохода          |
| O(N^k)            | k вложенных циклов                              | Полиномиальное время                         |
| O(2^N)            | Полный перебор подмножеств                      | Экспоненциальное, очень быстро растёт        |
| O(N!)             | Перестановки                                   | Факториальное, практически непригодно для N > 20 |

---

### Анализ алгоритмов: приемы и техники  
1. **Подсчёт основных операций**  
   Прикидываем доминирующие вложенные циклы и рекурсию, отбрасываем константы и низкоуровневые детали.  
2. **Разделяй и властвуй**  
   Рекурсивные отношения: T(N) = a·T(N/b) + O(N^d). По мастер-теореме получаем асимптотику.  
3. **Амортизированный анализ**  
   Когда отдельные операции могут быть дорогими, но в среднем на серию операций стоимость распределяется:  
   - Динамический массив (ArrayList): добавление амортизированно O(1) несмотря на редкое расширение O(N).  
   - Splay‑деревья: доступ амортизированно O(log N).  
4. **Хэш‑таблицы**  
   Lookup, вставка, удаление в среднем O(1), но в худшем случае O(N) при большом числе коллизий (редко при хорошей хеш‑функции).

---

### Пространственная сложность  
- **Константная O(1)** — алгоритм использует фиксированный объём дополнительной памяти.  
- **Линейная O(N)** — дополнительный массив или структура данных пропорциональны входу.  
- **Полиномиальная O(N^k)** — вложенные структуры.  
- **Рекурсивный стек** — глубина рекурсии T(N) может создавать O(N) стековых фреймов.

---

### Примеры анализа

#### Сортировка слиянием (Merge Sort)  
- Разделение пополам: 2 рекурсивных вызова T(N/2)  
- Слияние: O(N)  
- Итого: T(N) = 2·T(N/2) + O(N) → Θ(N log N)  
- Пространство: O(N) дополнительного массива для слияния.

#### Быстрая сортировка (Quick Sort)  
- В среднем: T(N) = 2·T(N/2) + O(N) → Θ(N log N)  
- Худший: T(N) = T(N-1) + O(N) → Θ(N²) (при неудачном разбиении)  
- Пространство: O(log N) рекурсии в среднем, O(N) в худшем.

#### Поиск в сбалансированном дереве (AVL, Red‑Black)  
- Высота h = O(log N)  
- Поиск/вставка/удаление: O(h) = O(log N)  
- Пространство: O(N) для хранения узлов.

---

### Практические советы  
- Всегда считайте асимптотику для больших N, константы у современных CPU часто меньше важны.  
- Сложность O(N log N) или лучше — целевой ориентир для «больших» объёмов (миллионы записей).  
- Для малых N могут быть эффективнее простые алгоритмы (сортировка вставками) из‑за низких констант.  
- Анализируйте худший и амортизированный случай для оценки пиковых затрат.  
- Учитывайте не только CPU, но и кэш‑поведения, параллельность и I/O — они могут нарушить классическую оценку.

---

Глубокое понимание алгоритмической сложности позволяет выбирать правильные структуры данных, прогнозировать масштабируемость системы и обосновывать архитектурные решения на уровне производительности.```
